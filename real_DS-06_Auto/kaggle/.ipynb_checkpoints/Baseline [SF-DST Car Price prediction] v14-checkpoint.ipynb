{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://whatcar.vn/media/2018/09/car-lot-940x470.jpg\"/>\n",
    "\n",
    "## Прогнозирование стоимости автомобиля по характеристикам\n",
    "*Этот Ноутбук является Примером/Шаблоном (Baseline) к этому соревнованию и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "\n",
    "> **baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline является хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помним, что по условию соревнования, нам нужно самостоятельно собрать обучающий датасет. В этом ноутбуке мы не будем рассматривать сбор данных. Предположим, что мы уже все собрали и просто подключили свой датасет через \"Add Data\", чтобы приступить к самому ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-421466f40522>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION    = 11\n",
    "DIR_TRAIN  = '../input/sf-autoru-solve-v4/' # подключил к ноутбуку свой внешний датасет\n",
    "DIR_TEST   = '../input/sf-dst-car-price/'\n",
    "VAL_SIZE   = 0.33   # 33%\n",
    "N_FOLDS    = 5\n",
    "\n",
    "# CATBOOST\n",
    "ITERATIONS = 2000\n",
    "LR         = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DIR_TRAIN+'train.csv') # мой подготовленный датасет для обучения модели\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['Таможня', 'Состояние', 'id'], axis=1, inplace=True,)\n",
    "    \n",
    "    \n",
    "    # ################### fix ############################################################## \n",
    "    # Переводим признаки из float в int (иначе catboost выдает ошибку)\n",
    "    for feature in ['modelDate', 'numberOfDoors', 'mileage', 'productionDate']:\n",
    "        df_output[feature]=df_output[feature].astype('int32')\n",
    "    \n",
    "    \n",
    "    # ################### Feature Engineering ####################################################\n",
    "    # тут ваш код на генерацию новых фитчей\n",
    "    # ....\n",
    "    \n",
    "    \n",
    "    # ################### Clean #################################################### \n",
    "    # убираем признаки которые еще не успели обработать, \n",
    "    df_output.drop(['Комплектация', 'description', 'Владение'], axis=1, inplace=True,)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preproc = preproc_data(train)\n",
    "X_sub = preproc_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preproc.drop(['car_url'], axis=1, inplace=True,) # убрал лишний столбец, которого нет в testе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_preproc.drop(['price'], axis=1,)\n",
    "y = train_preproc.price.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost\n",
    "![](https://pbs.twimg.com/media/DP-jUCyXcAArRTo.png:large)   \n",
    "\n",
    "\n",
    "У нас в данных практически все признаки категориальные. Специально для работы с такими данными была создана очень удобная библиотека CatBoost от Яндекса. [https://catboost.ai](http://)     \n",
    "На данный момент **CatBoost является одной из лучших библиотек для табличных данных!**\n",
    "\n",
    "#### Полезные видео о CatBoost (на русском):\n",
    "* [Доклад про CatBoost](https://youtu.be/9ZrfErvm97M)\n",
    "* [Свежий Туториал от команды CatBoost (практическая часть)](https://youtu.be/wQt4kgAOgV0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сat features\n",
    "CatBoost умеет самостоятельно обрабатывать категориальные признаки, но для корректной обработки нужно их указать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы не писать весь список этих признаков, просто вывел их через nunique(). и так сойдет)\n",
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep list of all categorical features in dataset to specify this for CatBoost\n",
    "cat_features_ids = np.where(X_train.apply(pd.Series.nunique) < 3000)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = ITERATIONS,\n",
    "                          learning_rate = LR,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE']\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "         cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, y_test),\n",
    "         verbose_eval=100,\n",
    "         use_best_model=True,\n",
    "         plot=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('catboost_single_model_baseline.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так просто со старта, даже не трогая сами данные и не подбирая настройки catboosta, получаем модель с уровнем ошибки в 14%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(X_sub)\n",
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['price'] = predict_submission\n",
    "sample_submission.to_csv(f'submission_v{VERSION}.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получили **MAPE 13%** на ЛБ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "![](https://github.com/itLek/sfml/raw/7e34d290e81921bcaa9d52a2236ec9c43b928e35/HW_lesson_03/img/ml.png)\n",
    "## CV\n",
    "Перед тем как бежать перебирать признаки и модели, поговорим о кросс-валидации ([CV](https://ru.wikipedia.org/wiki/Перекрёстная_проверка))\n",
    "\n",
    "Когда мы делаем отбор признаков или перебираем настройки модели, мы постоянно смотрим в тестовые данные (X_test), что может привести к подгону под тестовые данные. В итоге мы получим Переобучение (**overfitting**).     \n",
    "Чтобы избежать этого, можно сразу использовать кросс-валидацию по фолдам (подробнее в модуле *Классический Machine Learning >Модуль 7. Валидация данных >7.2. Разбиение выборки*). \n",
    "\n",
    "Ниже представлен Пример, как можно организовать обучение модели на 5 фолдах, с дальнейшим объединением предсказаний от каждой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_model(y_train, X_train, X_test, y_test):\n",
    "    model = CatBoostRegressor(iterations = ITERATIONS,\n",
    "                              learning_rate = LR,\n",
    "                              eval_metric='MAPE',\n",
    "                              random_seed = RANDOM_SEED,)\n",
    "    model.fit(X_train, y_train,\n",
    "              cat_features=cat_features_ids,\n",
    "              eval_set=(X_test, y_test),\n",
    "              verbose=False,\n",
    "              use_best_model=True,\n",
    "              plot=False)\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame(0,columns=[\"sub_1\"], index=sample_submission.index) # куда пишем предикты по каждой модели\n",
    "score_ls = []\n",
    "splits = list(KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED).split(X, y))\n",
    "\n",
    "for idx, (train_idx, test_idx) in tqdm(enumerate(splits), total=N_FOLDS,):\n",
    "    # use the indexes to extract the folds in the train and validation data\n",
    "    X_train, y_train, X_test, y_test = X.iloc[train_idx], y[train_idx], X.iloc[test_idx], y[test_idx]\n",
    "    # model for this fold\n",
    "    model = cat_model(y_train, X_train, X_test, y_test,)\n",
    "    # score model on test\n",
    "    test_predict = model.predict(X_test)\n",
    "    test_score = mape(y_test, test_predict)\n",
    "    score_ls.append(test_score)\n",
    "    print(f\"{idx+1} Fold Test MAPE: {mape(y_test, test_predict):0.3f}\")\n",
    "    # submissions\n",
    "    submissions[f'sub_{idx+1}'] = model.predict(X_sub)\n",
    "    model.save_model(f'catboost_fold_{idx+1}.model')\n",
    "    \n",
    "print(f'Mean Score: {np.mean(score_ls):0.3f}')\n",
    "print(f'Std Score: {np.std(score_ls):0.4f}')\n",
    "print(f'Max Score: {np.max(score_ls):0.3f}')\n",
    "print(f'Min Score: {np.min(score_ls):0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions['blend'] = (submissions.sum(axis=1))/len(submissions.columns)\n",
    "sample_submission['price'] = submissions['blend'].values\n",
    "sample_submission.to_csv(f'submission_blend_v{VERSION}.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вот так, простое усреднее предсказаний по фолдам позволило улучшить нам результат на 1%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking \n",
    "Давайте сначала разберемся, что-же такое этот Stacking. \n",
    "#### Начнем с Ансамбля моделей:     \n",
    "Допустим, вы обучили Различные модели. Теперь мы можем просто объединить их предсказания и получить средневзвешенное предсказание по всем моделям. При этом, чем разнообразней модели - тем лучше результат мы получим. Смотри пример на картинке \n",
    "![](https://github.com/rasbt/mlxtend/raw/master/docs/sources/img/ensemble_decision_regions_2d.png)\n",
    "\n",
    "#### А теперь Stacking:\n",
    "У нас есть предсказания от разных моделей, почему бы не использовать их как новые признаки/фитчи и не **построить поверх этих предсказаний новую модель**? Это основная идея Stacking-a. \n",
    "![](https://miro.medium.com/max/1892/0*GHYCJIjkkrP5ZgPh.png)\n",
    "Далее его еще можно бесконечно усложнять. Например, добавляя модели обученные на разных выборках и/или с разным составом признаков (bagging), или увеличивая уровни стекинга. В итоге мы можем получить что-то монструозное вроде этого:\n",
    "![](https://blogs.sas.com/content/subconsciousmusings/files/2017/05/stackedapproach.png)\n",
    "\n",
    "### Kaggle DarkSide\n",
    "Большинство победных решений на kaggle сейчас идет со стекингом. И это большой минус kaggle, так как завести такого монстра, в продакшен, на реальный онлайн сервис, практически нереально (я уже молчу про интерпретируемость подобного решения). При этом сам стекинг обычно не играет ключевую роль, но он позволяет докинуть доли процента, которые в соревновании могут оказаться критичными.\n",
    "\n",
    "<img src=\"http://www.quickmeme.com/img/c4/c4a179d0532ea1e02136d050ec961bd873597f7b70d561693cac4c161d06b26a.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* > Перед тем как отправляться \"во все тяжкие\" со Стекингом, рекомендую побольше поработать с Feature Engineering-ом.\n",
    "* > При Stacking-e Очень важно изначально продумать и выстроить четкие правила CV, чтоб не допустить утечки данных при обучении.   \n",
    "На крайний случай, можно воспользоваться готовыми пакетами с уже корректно реализованным Stacking-ом: [vecstack](https://github.com/vecxoz/vecstack), [mlxtend](http://rasbt.github.io/mlxtend/user_guide/regressor/StackingCVRegressor/),  [H2O](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "Или что еще можно сделать, чтоб улучшить результат:\n",
    "\n",
    "* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n",
    "* Сгенерировать новые признаки\n",
    "* Подгрузить еще больше данных\n",
    "* Попробовать подобрать параметры модели\n",
    "* Попробовать другие алгоритмы и библиотеки ML\n",
    "* Сделать Ансамбль моделей, Blending, Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
